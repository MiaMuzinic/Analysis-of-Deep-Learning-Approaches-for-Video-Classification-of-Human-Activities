# Analysis of Deep Learning Approaches for Video Classification of Human Activities: A Comparison of ConvLSTM and LRCN Architectures

As part of my graduate studies, I conducted a project comparing two deep learning architectures. This study evaluates ConvLSTM and LRCN models for classifying human activities in videos using the UCF50 dataset. ConvLSTM prioritizes temporal dependencies, while LRCN specializes in extracting spatial features. Both models demonstrate competitive performance across accuracy, precision, recall, and F1 score metrics. Notably, ConvLSTM requires higher computational resources due to increased parameters. These findings assist in selecting the appropriate model for specific video classification requirements. In this research, ConvLSTM achieved an accuracy of 77.05%, whereas LRCN reached 87.70% accuracy in identifying activities.


**Abstract**-In recent years, deep learning techniques have shown
remarkable success in video classification tasks. The
research focuses on evaluating and comparing differ-
ent state-of-the-art deep learning architectures, includ-
ing Convolutional Neural Networks (CNNs) and Recur-
rent Neural Networks (RNNs), in terms of their per-
formance and accuracy in classifying human activities
from video data. The aim of this research is to com-
pare metrics of ConvLSTM and LRCN deep learning
architectures for video classification of human activities
on the UCF50 dataset. ConvLSTM combines convolu-
tional and LSTM layers, capturing spatial and tempo-
ral dependencies, while LRCN integrates a pre-trained
CNN with an LSTM. Performance evaluation using ac-
curacy, precision, recall, and F1 score shows competi-
tive results for both architectures. ConvLSTM excels in
capturing temporal dependencies, while LRCN demon-
strates better spatial feature extraction. Computational
analysis reveals that ConvLSTM has higher computa-
tional requirements due to increased parameters and op-
erations. These findings provide insights for selecting ap-
propriate architectures based on specific video classifica-
tion requirements and computational constraints. In the
specific context mentioned, ConvLSTM demonstrated an
accuracy of 77.05%, and the LRCN model achieved an
accuracy of 87.70% in accurately identifying the activity
being performed.

**Keywords**: video classification, human activity
recognition, deep learning, convolutional neural net-
works, recurrent neural networks
